{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "11bde39e-dfcb-47df-b15f-4abe83cf9431",
      "metadata": {
        "id": "11bde39e-dfcb-47df-b15f-4abe83cf9431"
      },
      "source": [
        "# Fine-tuning Lag-Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f314d613-aac8-499f-a632-3a9062e1293e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f314d613-aac8-499f-a632-3a9062e1293e",
        "outputId": "7d679388-9bc0-4960-e553-cdd23dc67dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lag-llama'...\n",
            "remote: Enumerating objects: 294, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 294 (delta 101), reused 85 (delta 76), pack-reused 164\u001b[K\n",
            "Receiving objects: 100% (294/294), 224.14 KiB | 5.21 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/time-series-foundation-models/lag-llama/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9b3a4589-1ff7-46b3-8ad3-b2c2bc998183",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b3a4589-1ff7-46b3-8ad3-b2c2bc998183",
        "outputId": "22e1d0a1-7bd9-4f89-96ed-113ee16a698b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lag-llama\n"
          ]
        }
      ],
      "source": [
        "cd /content/lag-llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1cb4157e-a745-4938-b8c8-06eeeb57eeaa",
      "metadata": {
        "id": "1cb4157e-a745-4938-b8c8-06eeeb57eeaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676a900b-0f97-4bf4-d6c3-f7237adf2555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.1.4 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "80c5f8e7-3687-4f4c-8e42-2d84882845e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80c5f8e7-3687-4f4c-8e42-2d84882845e1",
        "outputId": "7462d531-bdaf-4688-d460-c86685a25fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'lag-llama.ckpt' to '/content/lag-llama/.huggingface/download/lag-llama.ckpt.b5a5c4b8a0cfe9b81bdac35ed5d88b5033cd119b5206c28e9cd67c4b45fb2c96.incomplete'\n",
            "lag-llama.ckpt: 100% 29.5M/29.5M [00:00<00:00, 52.5MB/s]\n",
            "Download complete. Moving file to /content/lag-llama/lag-llama.ckpt\n",
            "/content/lag-llama/lag-llama.ckpt\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli download time-series-foundation-models/Lag-Llama lag-llama.ckpt --local-dir /content/lag-llama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gluonts==0.14.4"
      ],
      "metadata": {
        "id": "bZIEvK8CL4d9",
        "outputId": "3a0c6b44-feef-42ca-cfbb-42bc4a61ae11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bZIEvK8CL4d9",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gluonts==0.14.4 in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (1.23.5)\n",
            "Requirement already satisfied: pandas<2.2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (2.1.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (2.7.3)\n",
            "Requirement already satisfied: tqdm~=4.23 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (4.66.4)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0->gluonts==0.14.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0->gluonts==0.14.4) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0->gluonts==0.14.4) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.14.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.14.4) (2.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.0,>=1.0->gluonts==0.14.4) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "12626ee4-7175-4854-8701-7cc6a4f514d8",
      "metadata": {
        "id": "12626ee4-7175-4854-8701-7cc6a4f514d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35256d40-8fca-4627-facd-58e0a6a69a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-eaf45c051a85>:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n",
            "/usr/local/lib/python3.10/dist-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from itertools import islice\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import torch\n",
        "\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from lag_llama.gluon.estimator import LagLlamaEstimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e4c2405a-be1c-4f7d-b598-580c974a68fb",
      "metadata": {
        "id": "e4c2405a-be1c-4f7d-b598-580c974a68fb"
      },
      "outputs": [],
      "source": [
        "def get_lag_llama_predictions(dataset,\n",
        "                              prediction_length,\n",
        "                              context_length=32,\n",
        "                              device=\"cuda\",\n",
        "                              num_samples=100,\n",
        "                              predictor=None):\n",
        "\n",
        "    ckpt = torch.load(\"lag-llama.ckpt\", map_location=device)\n",
        "    estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
        "\n",
        "    estimator = LagLlamaEstimator(\n",
        "        ckpt_path=\"lag-llama.ckpt\",\n",
        "        prediction_length=prediction_length,\n",
        "        context_length=context_length,\n",
        "        input_size=estimator_args[\"input_size\"],\n",
        "        n_layer=estimator_args[\"n_layer\"],\n",
        "        n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
        "        n_head=estimator_args[\"n_head\"],\n",
        "        scaling=estimator_args[\"scaling\"],\n",
        "        time_feat=estimator_args[\"time_feat\"],\n",
        "        num_parallel_samples=num_samples,\n",
        "    )\n",
        "\n",
        "    if predictor is None:\n",
        "      lightning_module = estimator.create_lightning_module()\n",
        "      transformation = estimator.create_transformation()\n",
        "      predictor = estimator.create_predictor(transformation, lightning_module)\n",
        "\n",
        "    forecasts = predictor.predict(\n",
        "        dataset=dataset\n",
        "    )\n",
        "\n",
        "    forecasts = list(forecasts)\n",
        "\n",
        "    return forecasts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "de228599-5404-4b62-87cd-4b9573583981",
      "metadata": {
        "id": "de228599-5404-4b62-87cd-4b9573583981"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "prediction_length = 8\n",
        "context_length = 128\n",
        "\n",
        "ckpt = torch.load(\"lag-llama.ckpt\", map_location=device)\n",
        "estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
        "\n",
        "estimator = LagLlamaEstimator(\n",
        "        ckpt_path=\"lag-llama.ckpt\",\n",
        "        prediction_length=prediction_length,\n",
        "        context_length=context_length,\n",
        "\n",
        "        input_size=estimator_args[\"input_size\"],\n",
        "        n_layer=estimator_args[\"n_layer\"],\n",
        "        n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
        "        n_head=estimator_args[\"n_head\"],\n",
        "        time_feat=estimator_args[\"time_feat\"],\n",
        "\n",
        "        # Fine-tuning arguments\n",
        "        nonnegative_pred_samples=True,\n",
        "        aug_prob=0,\n",
        "        lr=5e-4,\n",
        "        batch_size=64,\n",
        "        num_parallel_samples=20,\n",
        "        trainer_kwargs = {\"max_epochs\": 50,}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/marcopeix/FoundationModelsForTimeSeriesForecasting/main/data/walmart_sales_small.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df = df[df['Store'] == 1]\n",
        "\n",
        "input_df = df[:-8]\n",
        "test_df = df[-8:]\n",
        "\n",
        "input_df['Weekly_Sales'] = input_df['Weekly_Sales'].astype('float32')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RAwWDYacM86D",
        "outputId": "f558977c-d85c-4e92-b528-23bcb2e8f4e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RAwWDYacM86D",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-abc609e88630>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  input_df['Weekly_Sales'] = input_df['Weekly_Sales'].astype('float32')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ds = PandasDataset.from_long_dataframe(input_df, target='Weekly_Sales', item_id='Store')"
      ],
      "metadata": {
        "id": "YngUvVvpNwo2"
      },
      "id": "YngUvVvpNwo2",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7b2b75bd-657d-438b-8596-f97509253c92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9ac7f455fcc34969bda242d53f769c9b",
            "9ddd55f6074843c9b113361ebcccef60",
            "32caf0faaf0c417882acad8c3fe65c97",
            "14fba746be274dbca4f4163ca2ddf87c",
            "eea64b6de4bb4a4bb37d071ca9334af9",
            "e63111b96ac04570a20803eac5e45049",
            "62f140e389304218a3ea05c29b46eaf6",
            "37635957cf9f497fb98b4fe4046a971b",
            "5aa35b2196424336944754d1cda396da",
            "d119c1e5eb364582ae05bff3274fd5a6",
            "dbeeb4252b464eedabadbf17e33cd2db"
          ]
        },
        "id": "7b2b75bd-657d-438b-8596-f97509253c92",
        "outputId": "91b30a3e-5068-4032-a543-65f653cdec9b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "WARNING: Missing logger folder: /content/lag-llama/lightning_logs\n",
            "WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/lag-llama/lightning_logs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ac7f455fcc34969bda242d53f769c9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Epoch 0, global step 50: 'train_loss' reached 13.69628 (best 13.69628), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 13.69628 (best 13.69628), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 13.06870 (best 13.06870), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 13.06870 (best 13.06870), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 12.59574 (best 12.59574), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 12.59574 (best 12.59574), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 12.16357 (best 12.16357), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 12.16357 (best 12.16357), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 11.77250 (best 11.77250), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 11.77250 (best 11.77250), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 11.36296 (best 11.36296), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 11.36296 (best 11.36296), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' reached 11.06890 (best 11.06890), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' reached 11.06890 (best 11.06890), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=9-step=500.ckpt' as top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 10.95027 (best 10.95027), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 10.95027 (best 10.95027), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 10.86246 (best 10.86246), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 10.86246 (best 10.86246), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 10.81381 (best 10.81381), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 10.81381 (best 10.81381), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' reached 10.66395 (best 10.66395), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' reached 10.66395 (best 10.66395), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' reached 10.62660 (best 10.62660), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' reached 10.62660 (best 10.62660), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=15-step=800.ckpt' as top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 10.57212 (best 10.57212), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 10.57212 (best 10.57212), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 10.50636 (best 10.50636), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 10.50636 (best 10.50636), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 10.44474 (best 10.44474), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 10.44474 (best 10.44474), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 10.32858 (best 10.32858), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 10.32858 (best 10.32858), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' reached 10.29878 (best 10.29878), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' reached 10.29878 (best 10.29878), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=25-step=1300.ckpt' as top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 10.24316 (best 10.24316), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 10.24316 (best 10.24316), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' reached 10.22994 (best 10.22994), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' reached 10.22994 (best 10.22994), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=28-step=1450.ckpt' as top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' reached 10.22619 (best 10.22619), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' reached 10.22619 (best 10.22619), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=29-step=1500.ckpt' as top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' reached 10.16455 (best 10.16455), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' reached 10.16455 (best 10.16455), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=33-step=1700.ckpt' as top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached 10.15412 (best 10.15412), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached 10.15412 (best 10.15412), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached 10.13307 (best 10.13307), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached 10.13307 (best 10.13307), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' reached 10.09801 (best 10.09801), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' reached 10.09801 (best 10.09801), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=37-step=1900.ckpt' as top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' reached 10.09362 (best 10.09362), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' reached 10.09362 (best 10.09362), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=38-step=1950.ckpt' as top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached 10.05262 (best 10.05262), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached 10.05262 (best 10.05262), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' was not in top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' was not in top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' reached 10.05000 (best 10.05000), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' reached 10.05000 (best 10.05000), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=44-step=2250.ckpt' as top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' reached 9.99269 (best 9.99269), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' reached 9.99269 (best 9.99269), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=45-step=2300.ckpt' as top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' reached 9.95595 (best 9.95595), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' reached 9.95595 (best 9.95595), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=48-step=2450.ckpt' as top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n"
          ]
        }
      ],
      "source": [
        "predictor = estimator.train(input_ds, cache_data=True, shuffle_buffer_length=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "54a88620-5a56-463c-adf7-ef13018da432",
      "metadata": {
        "id": "54a88620-5a56-463c-adf7-ef13018da432"
      },
      "outputs": [],
      "source": [
        "finetune_forecasts = get_lag_llama_predictions(\n",
        "        dataset=input_ds,\n",
        "        prediction_length=prediction_length,\n",
        "        predictor=predictor,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3413cbf1-7e58-4c16-84a1-4c92d9926908",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3413cbf1-7e58-4c16-84a1-4c92d9926908",
        "outputId": "bcd32e2e-fe9c-402f-9c9c-fa51f091ba61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "finetune_forecasts[0].samples.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7e828749-354e-441a-bded-af2b254d6e14",
      "metadata": {
        "id": "7e828749-354e-441a-bded-af2b254d6e14"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_median_and_ci(data,\n",
        "                      start_date,\n",
        "                      horizon,\n",
        "                      freq,\n",
        "                      id,\n",
        "                      confidence=0.95):\n",
        "\n",
        "    n_samples, n_timesteps = data.shape\n",
        "\n",
        "    # Calculate the median for each timestep\n",
        "    medians = np.median(data, axis=0)\n",
        "\n",
        "    # Calculate the lower and upper percentile for the given confidence interval\n",
        "    lower_percentile = (1 - confidence) / 2 * 100\n",
        "    upper_percentile = (1 + confidence) / 2 * 100\n",
        "\n",
        "    # Calculate the lower and upper bounds for each timestep\n",
        "    lower_bounds = np.percentile(data, lower_percentile, axis=0)\n",
        "    upper_bounds = np.percentile(data, upper_percentile, axis=0)\n",
        "\n",
        "    pred_dates = pd.date_range(start=start_date, periods=horizon, freq=freq)\n",
        "    formatted_dates = pred_dates.strftime('%m-%d-%Y').tolist()\n",
        "\n",
        "    # Create a DataFrame with the results\n",
        "    df = pd.DataFrame({\n",
        "        'Date': formatted_dates,\n",
        "        'Store': id,\n",
        "        'Lag-Llama': medians,\n",
        "        f'Lag-Llama-lo-{int(confidence*100)}': lower_bounds,\n",
        "        f'Lag-Llama-hi-{int(confidence*100)}': upper_bounds\n",
        "    })\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_preds = get_median_and_ci(finetune_forecasts[0].samples,\n",
        "                                    start_date='2012-09-07',\n",
        "                                    horizon=8,\n",
        "                                    freq='W-FRI',\n",
        "                                    id=1,\n",
        "                                    confidence=0.80)\n",
        "\n",
        "finetuned_preds"
      ],
      "metadata": {
        "id": "vIJ6mEYERy1Q",
        "outputId": "4bb385ae-3e6d-4af0-9cd0-52f60442b6f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "id": "vIJ6mEYERy1Q",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date  Store    Lag-Llama  Lag-Llama-lo-80  Lag-Llama-hi-80\n",
              "0  09-07-2012      1  1626809.000     1.623364e+06     1.630248e+06\n",
              "1  09-14-2012      1  1559786.000     1.553144e+06     1.567084e+06\n",
              "2  09-21-2012      1  1478886.125     1.472061e+06     1.485673e+06\n",
              "3  09-28-2012      1  1561527.750     1.556464e+06     1.566646e+06\n",
              "4  10-05-2012      1  1811472.000     1.802887e+06     1.816306e+06\n",
              "5  10-12-2012      1  1584171.750     1.575350e+06     1.588324e+06\n",
              "6  10-19-2012      1  1536766.125     1.527896e+06     1.548808e+06\n",
              "7  10-26-2012      1  1523897.875     1.519111e+06     1.528638e+06"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3908bd53-18bc-4866-8a48-462b895f5d24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Store</th>\n",
              "      <th>Lag-Llama</th>\n",
              "      <th>Lag-Llama-lo-80</th>\n",
              "      <th>Lag-Llama-hi-80</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>09-07-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1626809.000</td>\n",
              "      <td>1.623364e+06</td>\n",
              "      <td>1.630248e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>09-14-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1559786.000</td>\n",
              "      <td>1.553144e+06</td>\n",
              "      <td>1.567084e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>09-21-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1478886.125</td>\n",
              "      <td>1.472061e+06</td>\n",
              "      <td>1.485673e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>09-28-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1561527.750</td>\n",
              "      <td>1.556464e+06</td>\n",
              "      <td>1.566646e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10-05-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1811472.000</td>\n",
              "      <td>1.802887e+06</td>\n",
              "      <td>1.816306e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10-12-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1584171.750</td>\n",
              "      <td>1.575350e+06</td>\n",
              "      <td>1.588324e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10-19-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1536766.125</td>\n",
              "      <td>1.527896e+06</td>\n",
              "      <td>1.548808e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10-26-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1523897.875</td>\n",
              "      <td>1.519111e+06</td>\n",
              "      <td>1.528638e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3908bd53-18bc-4866-8a48-462b895f5d24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3908bd53-18bc-4866-8a48-462b895f5d24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3908bd53-18bc-4866-8a48-462b895f5d24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f65f8a1-2f20-44c3-b941-57a4fe85e4ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f65f8a1-2f20-44c3-b941-57a4fe85e4ce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f65f8a1-2f20-44c3-b941-57a4fe85e4ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e85f0a84-7894-427b-ad03-bdd3fc47bea0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('finetuned_preds')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e85f0a84-7894-427b-ad03-bdd3fc47bea0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('finetuned_preds');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "finetuned_preds",
              "summary": "{\n  \"name\": \"finetuned_preds\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"09-14-2012\",\n          \"10-12-2012\",\n          \"09-07-2012\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Store\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lag-Llama\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1559786.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lag-Llama-lo-80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100653.05774564635,\n        \"min\": 1472061.1,\n        \"max\": 1802887.4625,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1553144.0125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lag-Llama-hi-80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100168.82045227799,\n        \"min\": 1485673.3375,\n        \"max\": 1816305.75,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1567083.925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mae_smape(pred_df, test_df, target_col, pred_col):\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    y_true = test_df[target_col].values\n",
        "    y_pred = pred_df[pred_col].values\n",
        "\n",
        "    # Calculate MAE\n",
        "    mae = int(np.mean(np.abs(y_true - y_pred)))\n",
        "\n",
        "    # Calculate sMAPE\n",
        "    denominator = np.abs(y_true) + np.abs(y_pred)\n",
        "    smape = round(np.mean(2.0 * np.abs(y_true - y_pred) / denominator) * 100,2)\n",
        "\n",
        "    return mae, smape"
      ],
      "metadata": {
        "id": "7IJJsgHwSHWV"
      },
      "id": "7IJJsgHwSHWV",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae_finetuned, smape_finetuned = calculate_mae_smape(finetuned_preds, test_df, 'Weekly_Sales', 'Lag-Llama')\n",
        "\n",
        "print(mae_finetuned, smape_finetuned)"
      ],
      "metadata": {
        "id": "sthEzou0SV13",
        "outputId": "4e94a431-6b20-4514-c750-a04072df1398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sthEzou0SV13",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54968 3.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45BiTe_4SdfQ"
      },
      "id": "45BiTe_4SdfQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ac7f455fcc34969bda242d53f769c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ddd55f6074843c9b113361ebcccef60",
              "IPY_MODEL_32caf0faaf0c417882acad8c3fe65c97",
              "IPY_MODEL_14fba746be274dbca4f4163ca2ddf87c"
            ],
            "layout": "IPY_MODEL_eea64b6de4bb4a4bb37d071ca9334af9"
          }
        },
        "9ddd55f6074843c9b113361ebcccef60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63111b96ac04570a20803eac5e45049",
            "placeholder": "​",
            "style": "IPY_MODEL_62f140e389304218a3ea05c29b46eaf6",
            "value": "Epoch 49: "
          }
        },
        "32caf0faaf0c417882acad8c3fe65c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37635957cf9f497fb98b4fe4046a971b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5aa35b2196424336944754d1cda396da",
            "value": 1
          }
        },
        "14fba746be274dbca4f4163ca2ddf87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d119c1e5eb364582ae05bff3274fd5a6",
            "placeholder": "​",
            "style": "IPY_MODEL_dbeeb4252b464eedabadbf17e33cd2db",
            "value": " 40/? [00:05&lt;00:00,  6.75it/s, v_num=0]"
          }
        },
        "eea64b6de4bb4a4bb37d071ca9334af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e63111b96ac04570a20803eac5e45049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62f140e389304218a3ea05c29b46eaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37635957cf9f497fb98b4fe4046a971b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa35b2196424336944754d1cda396da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d119c1e5eb364582ae05bff3274fd5a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbeeb4252b464eedabadbf17e33cd2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}