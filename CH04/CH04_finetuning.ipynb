{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "11bde39e-dfcb-47df-b15f-4abe83cf9431",
      "metadata": {
        "id": "11bde39e-dfcb-47df-b15f-4abe83cf9431"
      },
      "source": [
        "# Fine-tuning Lag-Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f314d613-aac8-499f-a632-3a9062e1293e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f314d613-aac8-499f-a632-3a9062e1293e",
        "outputId": "49790138-ba35-4ecc-c2c7-7c0d4122cb18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lag-llama'...\n",
            "remote: Enumerating objects: 294, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 294 (delta 102), reused 86 (delta 77), pack-reused 162\u001b[K\n",
            "Receiving objects: 100% (294/294), 224.13 KiB | 7.73 MiB/s, done.\n",
            "Resolving deltas: 100% (143/143), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/time-series-foundation-models/lag-llama/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9b3a4589-1ff7-46b3-8ad3-b2c2bc998183",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b3a4589-1ff7-46b3-8ad3-b2c2bc998183",
        "outputId": "a28e1c66-f9cc-45bb-99c2-ff1be319a770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lag-llama\n"
          ]
        }
      ],
      "source": [
        "cd /content/lag-llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1cb4157e-a745-4938-b8c8-06eeeb57eeaa",
      "metadata": {
        "id": "1cb4157e-a745-4938-b8c8-06eeeb57eeaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f70a19-3e19-4f2e-a983-a3f8863ec02e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.1.4 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "80c5f8e7-3687-4f4c-8e42-2d84882845e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80c5f8e7-3687-4f4c-8e42-2d84882845e1",
        "outputId": "69d5f03f-9a3f-4bd5-b36c-ddc21d28ca84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'lag-llama.ckpt' to '/content/lag-llama/.huggingface/download/lag-llama.ckpt.b5a5c4b8a0cfe9b81bdac35ed5d88b5033cd119b5206c28e9cd67c4b45fb2c96.incomplete'\n",
            "lag-llama.ckpt: 100% 29.5M/29.5M [00:00<00:00, 62.8MB/s]\n",
            "Download complete. Moving file to /content/lag-llama/lag-llama.ckpt\n",
            "/content/lag-llama/lag-llama.ckpt\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli download time-series-foundation-models/Lag-Llama lag-llama.ckpt --local-dir /content/lag-llama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gluonts==0.14.4"
      ],
      "metadata": {
        "id": "bZIEvK8CL4d9",
        "outputId": "a00ea7a0-164a-4fa0-eb13-88245574773e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bZIEvK8CL4d9",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gluonts==0.14.4 in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (1.23.5)\n",
            "Requirement already satisfied: pandas<2.2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (2.1.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (2.7.3)\n",
            "Requirement already satisfied: tqdm~=4.23 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (4.66.4)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.14.4) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0->gluonts==0.14.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0->gluonts==0.14.4) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0->gluonts==0.14.4) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.14.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.14.4) (2.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.0,>=1.0->gluonts==0.14.4) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "12626ee4-7175-4854-8701-7cc6a4f514d8",
      "metadata": {
        "id": "12626ee4-7175-4854-8701-7cc6a4f514d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa13c81d-9faf-4605-afd8-3fc65a4de2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-eaf45c051a85>:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n",
            "/usr/local/lib/python3.10/dist-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from itertools import islice\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import torch\n",
        "\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from lag_llama.gluon.estimator import LagLlamaEstimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e4c2405a-be1c-4f7d-b598-580c974a68fb",
      "metadata": {
        "id": "e4c2405a-be1c-4f7d-b598-580c974a68fb"
      },
      "outputs": [],
      "source": [
        "def get_lag_llama_predictions(dataset,\n",
        "                              prediction_length,\n",
        "                              context_length=32,\n",
        "                              device=\"cuda\",\n",
        "                              num_samples=100,\n",
        "                              predictor=None):\n",
        "\n",
        "    ckpt = torch.load(\"lag-llama.ckpt\", map_location=device)\n",
        "    estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
        "\n",
        "    estimator = LagLlamaEstimator(\n",
        "        ckpt_path=\"lag-llama.ckpt\",\n",
        "        prediction_length=prediction_length,\n",
        "        context_length=context_length,\n",
        "        input_size=estimator_args[\"input_size\"],\n",
        "        n_layer=estimator_args[\"n_layer\"],\n",
        "        n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
        "        n_head=estimator_args[\"n_head\"],\n",
        "        scaling=estimator_args[\"scaling\"],\n",
        "        time_feat=estimator_args[\"time_feat\"],\n",
        "        num_parallel_samples=num_samples,\n",
        "    )\n",
        "\n",
        "    if predictor is None:\n",
        "      lightning_module = estimator.create_lightning_module()\n",
        "      transformation = estimator.create_transformation()\n",
        "      predictor = estimator.create_predictor(transformation, lightning_module)\n",
        "\n",
        "    forecasts = predictor.predict(\n",
        "        dataset=dataset\n",
        "    )\n",
        "\n",
        "    forecasts = list(forecasts)\n",
        "\n",
        "    return forecasts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "de228599-5404-4b62-87cd-4b9573583981",
      "metadata": {
        "id": "de228599-5404-4b62-87cd-4b9573583981"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "prediction_length = 8\n",
        "context_length = 64\n",
        "\n",
        "ckpt = torch.load(\"lag-llama.ckpt\", map_location=device)\n",
        "estimator_args = ckpt[\"hyper_parameters\"][\"model_kwargs\"]\n",
        "\n",
        "estimator = LagLlamaEstimator(\n",
        "        ckpt_path=\"lag-llama.ckpt\",\n",
        "        prediction_length=prediction_length,\n",
        "        context_length=context_length,\n",
        "\n",
        "        input_size=estimator_args[\"input_size\"],\n",
        "        n_layer=estimator_args[\"n_layer\"],\n",
        "        n_embd_per_head=estimator_args[\"n_embd_per_head\"],\n",
        "        n_head=estimator_args[\"n_head\"],\n",
        "        time_feat=estimator_args[\"time_feat\"],\n",
        "\n",
        "        # Fine-tuning arguments\n",
        "        nonnegative_pred_samples=True,\n",
        "        aug_prob=0,\n",
        "        lr=5e-4,\n",
        "        batch_size=64,\n",
        "        num_parallel_samples=20,\n",
        "        trainer_kwargs = {\"max_epochs\": 50,}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/marcopeix/FoundationModelsForTimeSeriesForecasting/main/data/walmart_sales_small.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df = df[df['Store'] == 1]\n",
        "\n",
        "input_df = df[:-8]\n",
        "test_df = df[-8:]\n",
        "\n",
        "input_df['Weekly_Sales'] = input_df['Weekly_Sales'].astype('float32')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RAwWDYacM86D",
        "outputId": "d459bb5c-3bf9-4875-ad5e-38b0f03fdc7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RAwWDYacM86D",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-abc609e88630>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  input_df['Weekly_Sales'] = input_df['Weekly_Sales'].astype('float32')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ds = PandasDataset.from_long_dataframe(input_df, target='Weekly_Sales', item_id='Store')"
      ],
      "metadata": {
        "id": "YngUvVvpNwo2"
      },
      "id": "YngUvVvpNwo2",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7b2b75bd-657d-438b-8596-f97509253c92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2190665459db4bf68e161c73ab77e022",
            "bac497aad9d344e99c4999902ad38c2d",
            "5f53500cdc2344be963e19f80c630ebc",
            "c591def1ab6842a6bd6b08f8205aecc6",
            "e96c668e42a7433cb6e81dbd34cfdce3",
            "2b634c25f83049dcb0123c74ef126895",
            "58b660fcad6d465dba4634934d684534",
            "4d6299eefa2348e3b1579557faa9ee5d",
            "e072d213eab34deca6228f216fbe45b2",
            "604616432c4d46a7afef2c143b79430d",
            "3511248fcd8342deb08ad16a141395b9"
          ]
        },
        "id": "7b2b75bd-657d-438b-8596-f97509253c92",
        "outputId": "63f7e40c-19c0-4562-bd37-2fe8dfdea75b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "WARNING: Missing logger folder: /content/lag-llama/lightning_logs\n",
            "WARNING:lightning.pytorch.loggers.tensorboard:Missing logger folder: /content/lag-llama/lightning_logs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name          | Type               | Params\n",
            "-----------------------------------------------------\n",
            "0 | model         | LagLlamaModel      | 2.4 M \n",
            "1 | augmentations | ApplyAugmentations | 0     \n",
            "-----------------------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.797     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2190665459db4bf68e161c73ab77e022"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Epoch 0, global step 50: 'train_loss' reached 13.86050 (best 13.86050), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 0, global step 50: 'train_loss' reached 13.86050 (best 13.86050), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
            "INFO: Epoch 1, global step 100: 'train_loss' reached 13.10804 (best 13.10804), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 1, global step 100: 'train_loss' reached 13.10804 (best 13.10804), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
            "INFO: Epoch 2, global step 150: 'train_loss' reached 13.00644 (best 13.00644), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 2, global step 150: 'train_loss' reached 13.00644 (best 13.00644), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
            "INFO: Epoch 3, global step 200: 'train_loss' reached 12.76840 (best 12.76840), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 3, global step 200: 'train_loss' reached 12.76840 (best 12.76840), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
            "INFO: Epoch 4, global step 250: 'train_loss' reached 12.35226 (best 12.35226), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 4, global step 250: 'train_loss' reached 12.35226 (best 12.35226), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
            "INFO: Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 5, global step 300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 6, global step 350: 'train_loss' reached 12.22722 (best 12.22722), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 6, global step 350: 'train_loss' reached 12.22722 (best 12.22722), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
            "INFO: Epoch 7, global step 400: 'train_loss' reached 11.87549 (best 11.87549), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 7, global step 400: 'train_loss' reached 11.87549 (best 11.87549), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
            "INFO: Epoch 8, global step 450: 'train_loss' reached 11.50254 (best 11.50254), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 8, global step 450: 'train_loss' reached 11.50254 (best 11.50254), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
            "INFO: Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 9, global step 500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 10, global step 550: 'train_loss' reached 11.33164 (best 11.33164), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 10, global step 550: 'train_loss' reached 11.33164 (best 11.33164), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
            "INFO: Epoch 11, global step 600: 'train_loss' reached 11.13792 (best 11.13792), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 11, global step 600: 'train_loss' reached 11.13792 (best 11.13792), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
            "INFO: Epoch 12, global step 650: 'train_loss' reached 11.01560 (best 11.01560), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 12, global step 650: 'train_loss' reached 11.01560 (best 11.01560), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
            "INFO: Epoch 13, global step 700: 'train_loss' reached 10.91543 (best 10.91543), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 13, global step 700: 'train_loss' reached 10.91543 (best 10.91543), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=13-step=700.ckpt' as top 1\n",
            "INFO: Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 14, global step 750: 'train_loss' was not in top 1\n",
            "INFO: Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 15, global step 800: 'train_loss' was not in top 1\n",
            "INFO: Epoch 16, global step 850: 'train_loss' reached 10.77131 (best 10.77131), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 16, global step 850: 'train_loss' reached 10.77131 (best 10.77131), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
            "INFO: Epoch 17, global step 900: 'train_loss' reached 10.68706 (best 10.68706), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 17, global step 900: 'train_loss' reached 10.68706 (best 10.68706), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=17-step=900.ckpt' as top 1\n",
            "INFO: Epoch 18, global step 950: 'train_loss' reached 10.66264 (best 10.66264), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 18, global step 950: 'train_loss' reached 10.66264 (best 10.66264), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=18-step=950.ckpt' as top 1\n",
            "INFO: Epoch 19, global step 1000: 'train_loss' reached 10.58793 (best 10.58793), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 19, global step 1000: 'train_loss' reached 10.58793 (best 10.58793), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=19-step=1000.ckpt' as top 1\n",
            "INFO: Epoch 20, global step 1050: 'train_loss' reached 10.58251 (best 10.58251), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 20, global step 1050: 'train_loss' reached 10.58251 (best 10.58251), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
            "INFO: Epoch 21, global step 1100: 'train_loss' reached 10.53544 (best 10.53544), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 21, global step 1100: 'train_loss' reached 10.53544 (best 10.53544), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=21-step=1100.ckpt' as top 1\n",
            "INFO: Epoch 22, global step 1150: 'train_loss' reached 10.52451 (best 10.52451), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 22, global step 1150: 'train_loss' reached 10.52451 (best 10.52451), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=22-step=1150.ckpt' as top 1\n",
            "INFO: Epoch 23, global step 1200: 'train_loss' reached 10.51119 (best 10.51119), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 23, global step 1200: 'train_loss' reached 10.51119 (best 10.51119), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=23-step=1200.ckpt' as top 1\n",
            "INFO: Epoch 24, global step 1250: 'train_loss' reached 10.37045 (best 10.37045), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 24, global step 1250: 'train_loss' reached 10.37045 (best 10.37045), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
            "INFO: Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 26, global step 1350: 'train_loss' reached 10.35430 (best 10.35430), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 26, global step 1350: 'train_loss' reached 10.35430 (best 10.35430), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=26-step=1350.ckpt' as top 1\n",
            "INFO: Epoch 27, global step 1400: 'train_loss' reached 10.28270 (best 10.28270), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 27, global step 1400: 'train_loss' reached 10.28270 (best 10.28270), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=27-step=1400.ckpt' as top 1\n",
            "INFO: Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
            "INFO: Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
            "INFO: Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 31, global step 1600: 'train_loss' was not in top 1\n",
            "INFO: Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 32, global step 1650: 'train_loss' was not in top 1\n",
            "INFO: Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
            "INFO: Epoch 34, global step 1750: 'train_loss' reached 10.21908 (best 10.21908), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 34, global step 1750: 'train_loss' reached 10.21908 (best 10.21908), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=34-step=1750.ckpt' as top 1\n",
            "INFO: Epoch 35, global step 1800: 'train_loss' reached 10.21667 (best 10.21667), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 35, global step 1800: 'train_loss' reached 10.21667 (best 10.21667), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=35-step=1800.ckpt' as top 1\n",
            "INFO: Epoch 36, global step 1850: 'train_loss' reached 10.14236 (best 10.14236), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 36, global step 1850: 'train_loss' reached 10.14236 (best 10.14236), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=36-step=1850.ckpt' as top 1\n",
            "INFO: Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 37, global step 1900: 'train_loss' was not in top 1\n",
            "INFO: Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
            "INFO: Epoch 39, global step 2000: 'train_loss' reached 10.11288 (best 10.11288), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 39, global step 2000: 'train_loss' reached 10.11288 (best 10.11288), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=39-step=2000.ckpt' as top 1\n",
            "INFO: Epoch 40, global step 2050: 'train_loss' reached 10.10427 (best 10.10427), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 40, global step 2050: 'train_loss' reached 10.10427 (best 10.10427), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=40-step=2050.ckpt' as top 1\n",
            "INFO: Epoch 41, global step 2100: 'train_loss' reached 10.08130 (best 10.08130), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 41, global step 2100: 'train_loss' reached 10.08130 (best 10.08130), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=41-step=2100.ckpt' as top 1\n",
            "INFO: Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 42, global step 2150: 'train_loss' was not in top 1\n",
            "INFO: Epoch 43, global step 2200: 'train_loss' reached 10.06607 (best 10.06607), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 43, global step 2200: 'train_loss' reached 10.06607 (best 10.06607), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=43-step=2200.ckpt' as top 1\n",
            "INFO: Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
            "INFO: Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 45, global step 2300: 'train_loss' was not in top 1\n",
            "INFO: Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 46, global step 2350: 'train_loss' was not in top 1\n",
            "INFO: Epoch 47, global step 2400: 'train_loss' reached 10.01901 (best 10.01901), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 47, global step 2400: 'train_loss' reached 10.01901 (best 10.01901), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=47-step=2400.ckpt' as top 1\n",
            "INFO: Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 48, global step 2450: 'train_loss' was not in top 1\n",
            "INFO: Epoch 49, global step 2500: 'train_loss' reached 10.00773 (best 10.00773), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Epoch 49, global step 2500: 'train_loss' reached 10.00773 (best 10.00773), saving model to '/content/lag-llama/lightning_logs/version_0/checkpoints/epoch=49-step=2500.ckpt' as top 1\n",
            "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n"
          ]
        }
      ],
      "source": [
        "predictor = estimator.train(input_ds, cache_data=True, shuffle_buffer_length=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "54a88620-5a56-463c-adf7-ef13018da432",
      "metadata": {
        "id": "54a88620-5a56-463c-adf7-ef13018da432"
      },
      "outputs": [],
      "source": [
        "finetune_forecasts = get_lag_llama_predictions(\n",
        "        dataset=input_ds,\n",
        "        prediction_length=prediction_length,\n",
        "        predictor=predictor,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3413cbf1-7e58-4c16-84a1-4c92d9926908",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3413cbf1-7e58-4c16-84a1-4c92d9926908",
        "outputId": "a4b22d2a-f6f2-4eac-d9e6-e99d3b7cc2d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "finetune_forecasts[0].samples.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7e828749-354e-441a-bded-af2b254d6e14",
      "metadata": {
        "id": "7e828749-354e-441a-bded-af2b254d6e14"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_median_and_ci(data,\n",
        "                      start_date,\n",
        "                      horizon,\n",
        "                      freq,\n",
        "                      id,\n",
        "                      confidence=0.95):\n",
        "\n",
        "    n_samples, n_timesteps = data.shape\n",
        "\n",
        "    # Calculate the median for each timestep\n",
        "    medians = np.median(data, axis=0)\n",
        "\n",
        "    # Calculate the lower and upper percentile for the given confidence interval\n",
        "    lower_percentile = (1 - confidence) / 2 * 100\n",
        "    upper_percentile = (1 + confidence) / 2 * 100\n",
        "\n",
        "    # Calculate the lower and upper bounds for each timestep\n",
        "    lower_bounds = np.percentile(data, lower_percentile, axis=0)\n",
        "    upper_bounds = np.percentile(data, upper_percentile, axis=0)\n",
        "\n",
        "    pred_dates = pd.date_range(start=start_date, periods=horizon, freq=freq)\n",
        "    formatted_dates = pred_dates.strftime('%m-%d-%Y').tolist()\n",
        "\n",
        "    # Create a DataFrame with the results\n",
        "    df = pd.DataFrame({\n",
        "        'Date': formatted_dates,\n",
        "        'Store': id,\n",
        "        'Lag-Llama': medians,\n",
        "        f'Lag-Llama-lo-{int(confidence*100)}': lower_bounds,\n",
        "        f'Lag-Llama-hi-{int(confidence*100)}': upper_bounds\n",
        "    })\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_preds = get_median_and_ci(finetune_forecasts[0].samples,\n",
        "                                    start_date='2012-09-07',\n",
        "                                    horizon=8,\n",
        "                                    freq='W-FRI',\n",
        "                                    id=1,\n",
        "                                    confidence=0.80)\n",
        "\n",
        "finetuned_preds"
      ],
      "metadata": {
        "id": "vIJ6mEYERy1Q",
        "outputId": "e022362b-f818-4ba5-83b7-9a1ce1250b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "id": "vIJ6mEYERy1Q",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date  Store    Lag-Llama  Lag-Llama-lo-80  Lag-Llama-hi-80\n",
              "0  09-07-2012      1  1646512.250     1.641362e+06     1.657577e+06\n",
              "1  09-14-2012      1  1616172.500     1.608035e+06     1.621749e+06\n",
              "2  09-21-2012      1  1516381.000     1.510720e+06     1.520407e+06\n",
              "3  09-28-2012      1  1566029.750     1.560994e+06     1.572415e+06\n",
              "4  10-05-2012      1  1755081.125     1.750029e+06     1.761098e+06\n",
              "5  10-12-2012      1  1628259.750     1.621195e+06     1.632376e+06\n",
              "6  10-19-2012      1  1501428.000     1.497410e+06     1.509792e+06\n",
              "7  10-26-2012      1  1569666.750     1.562812e+06     1.574566e+06"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba3beeda-0723-476c-a59a-2ed8ce9003bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Store</th>\n",
              "      <th>Lag-Llama</th>\n",
              "      <th>Lag-Llama-lo-80</th>\n",
              "      <th>Lag-Llama-hi-80</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>09-07-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1646512.250</td>\n",
              "      <td>1.641362e+06</td>\n",
              "      <td>1.657577e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>09-14-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1616172.500</td>\n",
              "      <td>1.608035e+06</td>\n",
              "      <td>1.621749e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>09-21-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1516381.000</td>\n",
              "      <td>1.510720e+06</td>\n",
              "      <td>1.520407e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>09-28-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1566029.750</td>\n",
              "      <td>1.560994e+06</td>\n",
              "      <td>1.572415e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10-05-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1755081.125</td>\n",
              "      <td>1.750029e+06</td>\n",
              "      <td>1.761098e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10-12-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1628259.750</td>\n",
              "      <td>1.621195e+06</td>\n",
              "      <td>1.632376e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10-19-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1501428.000</td>\n",
              "      <td>1.497410e+06</td>\n",
              "      <td>1.509792e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10-26-2012</td>\n",
              "      <td>1</td>\n",
              "      <td>1569666.750</td>\n",
              "      <td>1.562812e+06</td>\n",
              "      <td>1.574566e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba3beeda-0723-476c-a59a-2ed8ce9003bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba3beeda-0723-476c-a59a-2ed8ce9003bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba3beeda-0723-476c-a59a-2ed8ce9003bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f37e2c82-4764-42db-b2ce-617ecd36f705\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f37e2c82-4764-42db-b2ce-617ecd36f705')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f37e2c82-4764-42db-b2ce-617ecd36f705 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4a99cf23-ebe8-4be5-9f39-e3d70910c8fa\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('finetuned_preds')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4a99cf23-ebe8-4be5-9f39-e3d70910c8fa button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('finetuned_preds');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "finetuned_preds",
              "summary": "{\n  \"name\": \"finetuned_preds\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"09-14-2012\",\n          \"10-12-2012\",\n          \"09-07-2012\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Store\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lag-Llama\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1616172.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lag-Llama-lo-80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80933.97387514649,\n        \"min\": 1497410.0625,\n        \"max\": 1750029.275,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1608035.3625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lag-Llama-hi-80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 81378.18966868338,\n        \"min\": 1509791.7375,\n        \"max\": 1761097.6625,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1621749.1875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mae_smape(pred_df, test_df, target_col, pred_col):\n",
        "\n",
        "    # Extract the relevant columns\n",
        "    y_true = test_df[target_col].values\n",
        "    y_pred = pred_df[pred_col].values\n",
        "\n",
        "    # Calculate MAE\n",
        "    mae = int(np.mean(np.abs(y_true - y_pred)))\n",
        "\n",
        "    # Calculate sMAPE\n",
        "    denominator = np.abs(y_true) + np.abs(y_pred)\n",
        "    smape = round(np.mean(2.0 * np.abs(y_true - y_pred) / denominator) * 100,2)\n",
        "\n",
        "    return mae, smape"
      ],
      "metadata": {
        "id": "7IJJsgHwSHWV"
      },
      "id": "7IJJsgHwSHWV",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae_finetuned, smape_finetuned = calculate_mae_smape(finetuned_preds, test_df, 'Weekly_Sales', 'Lag-Llama')\n",
        "\n",
        "print(mae_finetuned, smape_finetuned)"
      ],
      "metadata": {
        "id": "sthEzou0SV13",
        "outputId": "ba0248a9-e87a-4079-8d03-149e8ec0a93a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sthEzou0SV13",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59419 3.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45BiTe_4SdfQ"
      },
      "id": "45BiTe_4SdfQ",
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2190665459db4bf68e161c73ab77e022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bac497aad9d344e99c4999902ad38c2d",
              "IPY_MODEL_5f53500cdc2344be963e19f80c630ebc",
              "IPY_MODEL_c591def1ab6842a6bd6b08f8205aecc6"
            ],
            "layout": "IPY_MODEL_e96c668e42a7433cb6e81dbd34cfdce3"
          }
        },
        "bac497aad9d344e99c4999902ad38c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b634c25f83049dcb0123c74ef126895",
            "placeholder": "​",
            "style": "IPY_MODEL_58b660fcad6d465dba4634934d684534",
            "value": "Epoch 49: "
          }
        },
        "5f53500cdc2344be963e19f80c630ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d6299eefa2348e3b1579557faa9ee5d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e072d213eab34deca6228f216fbe45b2",
            "value": 1
          }
        },
        "c591def1ab6842a6bd6b08f8205aecc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_604616432c4d46a7afef2c143b79430d",
            "placeholder": "​",
            "style": "IPY_MODEL_3511248fcd8342deb08ad16a141395b9",
            "value": " 40/? [00:03&lt;00:00, 12.13it/s, v_num=0]"
          }
        },
        "e96c668e42a7433cb6e81dbd34cfdce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2b634c25f83049dcb0123c74ef126895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58b660fcad6d465dba4634934d684534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d6299eefa2348e3b1579557faa9ee5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e072d213eab34deca6228f216fbe45b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "604616432c4d46a7afef2c143b79430d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3511248fcd8342deb08ad16a141395b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}